{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7bfb7c5a-e145-49ed-adb7-be1802339d86",
      "metadata": {
        "id": "7bfb7c5a-e145-49ed-adb7-be1802339d86",
        "tags": []
      },
      "source": [
        "# IFT 6758 - Devoir 4\n",
        "\n",
        "### Interprétabilité du modèle, Explicabilité, Sélection et Ingénierie de caractéristiques\n",
        "\n",
        "**Ce devoir a pour objectif de vous donner plus d'expérience pratique dans les domaines de l'interprétabilité du modèle, de la sélection des caractéristiques et de l'ingénierie des caractéristiques.**\n",
        "\n",
        "Évaluation dans ce jupyter notebook :\n",
        "\n",
        "- Sorties et graphiques\n",
        "- Résultats imprimés issus de l'exécution de fonctions\n",
        "- Questions à réponse courte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06160bcc-d246-4765-a862-18e6ce364ad1",
      "metadata": {
        "id": "06160bcc-d246-4765-a862-18e6ce364ad1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import eli5\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from hw4 import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d31ec38",
      "metadata": {},
      "source": [
        "# Partie 1 : Interprétabilité et Explicabilité du Modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aeda9a9-d48c-44bb-9352-fd813652b603",
      "metadata": {
        "id": "6aeda9a9-d48c-44bb-9352-fd813652b603",
        "tags": []
      },
      "source": [
        "## 1. Chargement des Données"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c577daef-6bb6-4fe7-940f-f8f5801b6248",
      "metadata": {
        "id": "c577daef-6bb6-4fe7-940f-f8f5801b6248"
      },
      "source": [
        "### Chargement de l'ensemble de données des réadmissions\n",
        "\n",
        "Nous commencerons par charger notre ensemble de données et vérifier un petit échantillon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520c7577-69ce-4a1f-b3d2-95a4d5e4c8a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "520c7577-69ce-4a1f-b3d2-95a4d5e4c8a5",
        "outputId": "9efaf3d4-8757-4d34-bea8-8a47e3983d16"
      },
      "outputs": [],
      "source": [
        "path = \"data/hospital.csv\"\n",
        "raw_df = load_data(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a0c309-c7d3-4c96-bedf-777301f7f62d",
      "metadata": {
        "id": "06a0c309-c7d3-4c96-bedf-777301f7f62d"
      },
      "outputs": [],
      "source": [
        "# Vérification d'un échantillon de 5 patients\n",
        "np.random.seed(0)\n",
        "raw_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebcfc6b",
      "metadata": {},
      "source": [
        "Nous pouvons vérifier les noms de toutes les colonnes de notre ensemble de données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ae9d5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérification des noms des 65 colonnes de notre ensemble de données\n",
        "raw_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc67679",
      "metadata": {},
      "source": [
        "Nous pouvons également vérifier leurs types de données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef34ba55-5682-4b27-8c24-f3d04507456c",
      "metadata": {
        "id": "ef34ba55-5682-4b27-8c24-f3d04507456c"
      },
      "outputs": [],
      "source": [
        "# Vérification des types de données du dataframe brut\n",
        "raw_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd470256",
      "metadata": {},
      "source": [
        "Ici, vous avez un bref aperçu de la manière d'interpréter chaque nom de colonne :\n",
        "\n",
        "- La colonne portant le nom `is_readmitted` est notre cible de prédiction. C'est ce que notre modèle devrait être en mesure de classifier correctement. Remarquez que les valeurs de cette colonne sont booléennes et que nous devrons les mapper en 1 et 0 avant d'entraîner notre modèle.\n",
        "- Les colonnes avec le mot `diag` indiquent le code de diagnostic de la maladie ou des maladies pour lesquelles le patient a été admis. Par exemple, `diag_1_428` signifie que le médecin a donné le diagnostic de la première maladie comme \"428\". Ces codes pourraient être consultés dans un répertoire de codes médicaux, mais sans plus d'informations médicales, ils ne signifieraient rien pour nous de toute façon.\n",
        "- Les colonnes avec des noms comme `glimepiride_No` signifient que le patient n'a pas pris le médicament `x`. Dans cet exemple, le médicament est `glimepiride`. Si cette caractéristique avait une valeur de False, cela signifierait que le patient a pris le médicament `glimepiride`.\n",
        "- Les caractéristiques dont les noms commencent par `medical_specialty` décrivent la spécialité du médecin qui voit le patient. Les valeurs de ces champs sont toutes `True` ou `False`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de21d6f8",
      "metadata": {},
      "source": [
        "Nous vérifions s'il y a des valeurs manquantes dans notre ensemble de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e1099c-035d-4a50-8964-7779d5b648ec",
      "metadata": {
        "id": "07e1099c-035d-4a50-8964-7779d5b648ec"
      },
      "outputs": [],
      "source": [
        "# Vérifier s'il y a des valeurs manquantes (NA)\n",
        "raw_df.isna().any(axis=1).sum() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8878ae4d",
      "metadata": {},
      "source": [
        "Enfin, nous encoderons notre cible de prédiction. Complétez la méthode `encode_target_column()` dans `hw4.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9700db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : compléter la méthode encode_target_column() dans hw4.py\n",
        "df = encode_target_column(raw_df)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b67982-37d5-4e9c-a2d9-807d31be50ed",
      "metadata": {
        "id": "61b67982-37d5-4e9c-a2d9-807d31be50ed"
      },
      "source": [
        "## 2. Interprétation du Modèle\n",
        "\n",
        "Imaginons que nous ayons choisi un modèle simple qui prédit si un patient sera réadmis à l'hôpital, mais les médecins (nos principales parties prenantes) disent qu'ils ne savent pas comment évaluer un modèle et ils aimeraient que nous leur montrions des preuves que le modèle est en ligne avec leur intuition médicale.\n",
        "\n",
        "Ils sont très occupés à sauver des vies et ils n'ont pas le temps pour des graphiques ou des rapports compliqués. Nous devons produire une représentation qui résume notre aperçu du modèle en 1 ou 2 graphiques."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f4cbf2",
      "metadata": {},
      "source": [
        "Tout d'abord, nous devons préparer notre ensemble de données pour l'entraînement du modèle et l'évaluation du modèle. Nous utiliserons la fonction `split_data()` de notre fichier `hw4.py` pour diviser notre ensemble de données en X_train, y_train, X_val et y_val. Nous sommes de jeunes scientifiques des données et nous croyons que toutes les fonctionnalités sont utiles pour prédire si un patient sera réadmis (je sais que vous savez que c'est faux, mais jouons le jeu pour l'exercice)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747820df-2d1f-44b5-92aa-9e952730d361",
      "metadata": {
        "id": "747820df-2d1f-44b5-92aa-9e952730d361"
      },
      "outputs": [],
      "source": [
        "# Diviser l'ensemble de données en ensembles d'entraînement et de validation\n",
        "X_train, X_val, y_train, y_val = split_data(df, \"is_readmitted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bbfa349",
      "metadata": {},
      "source": [
        "Le modèle que nous avons choisi est un modèle de `Random Forest`. Nous allons entraîner et tester notre modèle sur les subdivisions de la cellule précédente. Ici, vous devrez compléter la méthode `train_random_forest()` du fichier `hw4.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd092db-fc9f-45ce-bb63-1c0857c3d9ac",
      "metadata": {
        "id": "8bd092db-fc9f-45ce-bb63-1c0857c3d9ac"
      },
      "outputs": [],
      "source": [
        "# TODO: compléter la méthode train_random_forest() dans hw4.py\n",
        "firstModel = train_random_forest(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31aaf8e3",
      "metadata": {},
      "source": [
        "Nous sommes novices dans le domaine de la science des données médicales, mais nous savons qu'un rapport de classification pourrait nous aider à montrer que le modèle effectue son travail. Ici, vous devrez compléter la méthode `evaluate_model()` de `hw4.py`, car elle nous aidera à obtenir la précision de notre modèle et notre rapport de classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83942ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: complete the method evaluate_model() in hw4.py\n",
        "acc, report = evaluate_model(firstModel, X_val,y_val)\n",
        "print(f\"The accuracy of our model is: {acc}\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e74f1b1",
      "metadata": {},
      "source": [
        "### 2.1 Importance des Caractéristiques\n",
        "\n",
        "Ouch ! Nous n'avons pas fait très bien. Cependant, la science des données est un processus d'amélioration continue, et nous savons que nous pourrions améliorer ce modèle si nous comprenons comment nos caractéristiques interagissent avec notre modèle.\n",
        "\n",
        "Nous restons calmes et nous nous souvenons que nous pouvons interroger notre modèle pour identifier les caractéristiques qui ont le plus d'impact sur la prédiction. Il existe plusieurs façons de le faire, mais nous décidons de travailler avec l'`importance par permutation` (elle est rapide à calculer, largement utilisée et comprise, et elle est conforme aux propriétés que nous souhaiterions qu'une mesure d'importance des caractéristiques ait).\n",
        "\n",
        "L'importance par permutation est calculée après qu'un modèle a été ajusté. Nous ne changerons pas le modèle ni les prédictions que nous obtiendrions pour un ensemble de caractéristiques donné. Cette mesure nous aidera à répondre à la question : Si je mélange aléatoirement une colonne unique des données de validation, en laissant la cible et toutes les autres colonnes en place, comment cela affecterait-il la précision des prédictions dans ces données maintenant mélangées ? L'intuition derrière cela est que la précision du modèle souffre particulièrement si nous mélangeons une colonne sur laquelle le modèle s'appuie fortement pour ses prédictions.\n",
        "\n",
        "Ici, vous devrez compléter la méthode `calculate_permutation_importance()`, qui nous permettra de calculer les importances par permutation des caractéristiques utilisées. Nous les montrerons ensuite à l'aide de la fonction `eli5.show_weights()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d73c63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compléter la méthode calculate_permutation_importance dans hw4.py\n",
        "feature_names = X_val.columns.tolist()\n",
        "perm = calculate_permutation_importance(firstModel, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed559ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "eli5.show_weights(perm, feature_names = X_val.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd8de41c",
      "metadata": {},
      "source": [
        "**Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd75781f",
      "metadata": {},
      "source": [
        "1-. Quelle semble être la caractéristique la plus importante ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f10d7fbc",
      "metadata": {},
      "source": [
        "*Votre réponse*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1479ade",
      "metadata": {},
      "source": [
        "---------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b1c9887",
      "metadata": {},
      "source": [
        "**Interprétation des Importances par Permutation**\n",
        "\n",
        "Les valeurs en haut sont les caractéristiques les plus importantes, et celles en bas sont les moins importantes.\n",
        "\n",
        "Le premier nombre dans chaque ligne indique de combien les performances du modèle ont diminué avec un mélange aléatoire (dans ce cas, en utilisant \"l'exactitude\" comme mesure de performance). Le nombre après le ± mesure comment les performances ont varié d'un mélange à l'autre.\n",
        "\n",
        "Il est possible de voir des valeurs négatives pour les importances par permutation. Dans ces cas, les prédictions sur les données mélangées (ou bruitées) se sont avérées plus précises que sur les données réelles. Cela se produit lorsque la caractéristique n'avait pas d'importance (elle aurait dû avoir une importance proche de 0), mais le hasard a fait que les prédictions sur les données mélangées étaient plus précises."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68087013",
      "metadata": {},
      "source": [
        "----------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f839c2d9",
      "metadata": {},
      "source": [
        "### 2.2 Graphiques de Dépendance Partielle\n",
        "\n",
        "Nous montrons nos conclusions aux médecins. Ils ne semblent pas trop impressionnés par les performances de notre modèle, mais ils aimeraient en savoir plus sur la caractéristique que le modèle a identifiée comme la plus importante. Nous allons créer un graphique pour leur montrer comment la caractéristique principale affecte les prédictions du modèle. Pour ce faire, vous devrez compléter la méthode `plot_partial_dependence()` de `solution.py`, qui nous aidera à afficher un graphique de dépendance partielle.\n",
        "\n",
        "Alors que l'importance des caractéristiques montre quelles variables affectent le plus les prédictions, les graphiques de dépendance partielle montrent comment une caractéristique affecte les prédictions. Si vous êtes familier avec les modèles de régression linéaire ou logistique, les graphiques de dépendance partielle peuvent être interprétés de manière similaire aux coefficients de ces modèles. Cependant, les graphiques de dépendance partielle sur des modèles sophistiqués peuvent capturer des motifs plus complexes que les coefficients des modèles simples.\n",
        "\n",
        "Les graphiques de dépendance partielle sont calculés après qu'un modèle a été ajusté. Le modèle est ajusté sur des données réelles qui n'ont pas été manipulées de quelque manière que ce soit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bbbeab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compléter la méthode plot_partial_dependence() dans hw4.py et attribuer le nom de la caractéristique la plus importante que nous avons trouvée à la variable topFeature.\n",
        "topFeature=\"number_inpatient\"\n",
        "plot_partial_dependence(firstModel,X_val,topFeature)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9439e9",
      "metadata": {},
      "source": [
        "Nous montrons notre graphique aux médecins et ils pensent que c'est un bon signe que l'augmentation du nombre de procédures hospitalières entraîne une augmentation des prédictions. Mais ils ne peuvent pas dire à partir de ce graphique si ce changement est important ou non. Ils aimeraient que nous en fassions un semblable pour `time_in_hospital` pour voir comment cela se compare. Voyons comment ça se passe :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fc3d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_partial_dependence(firstModel,X_val,\"time_in_hospital\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6159170f",
      "metadata": {},
      "source": [
        "Il semble que `time_in_hospital` n'ait aucune importance du tout. La différence entre la valeur la plus basse sur le graphique de dépendance partielle et la valeur la plus élevée est d'environ 5 %.\n",
        "\n",
        "Si c'est ce que notre modèle a conclu, les médecins le croiront. Mais pour eux, cela semble si faible. Est-il possible que les données soient incorrectes, ou notre modèle fait-il quelque chose de plus complexe que ce à quoi ils s'attendent ?\n",
        "\n",
        "Ils aimeraient que nous leur montrions le taux de réadmission brut pour chaque valeur de `time_in_hospital` pour voir comment cela se compare au graphique de dépendance partielle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08efc32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compléter la méthode plot_mean_readmission_vs_time() dans hw4.py.\n",
        "plot_mean_readmission_vs_time(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4834f5",
      "metadata": {},
      "source": [
        "## 3. Explicabilité du Modèle (Bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff5b01b",
      "metadata": {},
      "source": [
        "### 3.1 Valeurs SHAP\n",
        "\n",
        "Après avoir visionné cela, les médecins sont convaincus que nous avons les bonnes données, et un aperçu du modèle semblait raisonnable pour un premier essai. Il est temps de transformer cela en un produit fini qu'ils peuvent utiliser et tester (dans la vraie vie, cela ne se produirait pas, car les modèles doivent passer une série de contrôles et de réglementations stricts avant d'être utilisés dans des environnements médicaux réels, mais l'idée ici est de vous montrer comment utiliser ces outils et d'être suffisamment familiarisé pour les appliquer dans notre projet de cours). Plus précisément, l'hôpital souhaite que vous créiez une fonction `main_factors()` qui fait ce qui suit :\n",
        "- Prend une seule ligne de données de patient (du même format que nos données traitées)\n",
        "- Crée une visualisation montrant quelles caractéristiques de ce patient ont augmenté leur risque de réadmission, quelles caractéristiques l'ont diminué, et dans quelle mesure ces caractéristiques ont de l'importance.\n",
        "\n",
        "Il n'est pas important de montrer chaque caractéristique avec chaque impact minuscule sur le risque de réadmission. Il est acceptable de se concentrer uniquement sur les caractéristiques les plus importantes pour ce patient."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726a7011",
      "metadata": {},
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64102a97",
      "metadata": {},
      "source": [
        "Jusqu'à présent, nous avons travaillé avec certaines techniques pour extraire des informations générales à partir d'un modèle d'apprentissage automatique. Mais que se passe-t-il si nous voulons décomposer le fonctionnement du modèle pour une prédiction individuelle ?\n",
        "\n",
        "Les valeurs SHAP (un acronyme de SHapley Additive exPlanations) décomposent une prédiction pour montrer l'impact de chaque caractéristique. Où pourriez-vous utiliser cela ? Imaginez les scénarios suivants :\n",
        "\n",
        "    - Un modèle indique qu'une banque ne devrait pas accorder un prêt à quelqu'un, et la banque est légalement tenue d'expliquer les raisons de chaque refus de prêt (nous commençons à voir de plus en plus de réglementations exigeant de l'explicabilité des modèles pour ce type d'applications en ML).\n",
        "    - Un fournisseur de soins de santé souhaite identifier les facteurs qui influent sur le risque de contracter une maladie pour chaque patient, afin de pouvoir intervenir directement sur ces facteurs de risque avec des interventions médicales ciblées (c'est également important d'un point de vue réglementaire, car les fournisseurs de soins de santé doivent fournir des preuves claires sur la manière dont un patient a été diagnostiqué et la raison derrière un plan de traitement spécifique).\n",
        "\n",
        "**Comment fonctionnent les valeurs SHAP ?**\n",
        "\n",
        "Les valeurs SHAP interprètent l'impact d'avoir une certaine valeur pour une caractéristique donnée par rapport à la prédiction que nous ferions si cette caractéristique prenait une valeur de référence. Les valeurs SHAP le font de manière à garantir une belle propriété. Plus précisément, vous décomposez une prédiction avec l'équation suivante :\n",
        "\n",
        "somme(des valeurs SHAP de toutes les caractéristiques) = prédiction_pour_réadmission - prédiction_pour_valeurs_de_base\n",
        "\n",
        "C'est-à-dire que les valeurs SHAP de toutes les caractéristiques se cumulent pour expliquer pourquoi ma prédiction était différente de la valeur de base. Cela nous aide à expliquer pourquoi le modèle a identifié un patient pour une réadmission ou non."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "349f315f",
      "metadata": {},
      "source": [
        "--------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff643daa",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_patient = X_val.iloc[0].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27bc28ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: compléter la méthode main_factors() dans hw4.py.\n",
        "main_factors(firstModel,sample_patient)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2d10c3",
      "metadata": {},
      "source": [
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cb33bc",
      "metadata": {},
      "source": [
        "**Comment interprétez-vous cela ?**\n",
        "\n",
        "Les valeurs des caractéristiques qui augmentent les prédictions sont en rouge, et leur taille visuelle montre l'ampleur de l'effet de la caractéristique. Les valeurs des caractéristiques qui diminuent la prédiction sont en bleu.\n",
        "\n",
        "Si vous soustrayez la longueur des barres bleues de la longueur des barres rouges, cela équivaut à la distance de la valeur de base à la sortie.\n",
        "\n",
        "Il y a une certaine complexité dans la technique, pour s'assurer que la valeur de base plus la somme des effets individuels s'ajoutent à la prédiction (ce qui n'est pas aussi simple que cela en a l'air). Nous n'entrerons pas dans les détails ici, car ce n'est pas essentiel pour l'utilisation de la technique. Cet article de blog propose une explication théorique plus longue : https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365398c5",
      "metadata": {},
      "source": [
        "----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b3cd92",
      "metadata": {},
      "source": [
        "**Question (Bonus)**\n",
        "\n",
        "Comment interpréteriez-vous la visualisation des valeurs SHAP que nous avons obtenue ? Quels facteurs de risque augmentent le taux de réadmission et lesquels le diminuent réellement ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf5e931",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e3e815",
      "metadata": {},
      "source": [
        "# Partie 2 : Sélection de Caractéristiques et Ingénierie des Caractéristiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26355500",
      "metadata": {},
      "source": [
        "Dans cette deuxième partie de l'exercice, nous explorerons les sujets de la sélection de caractéristiques et de l'ingénierie des caractéristiques. Nous travaillerons avec un ensemble de données de prévision des tarifs de taxi de la ville de New York. Cet ensemble de données est plus gérable que notre ensemble de données précédent et nous permettra d'effectuer une sélection de caractéristiques et une ingénierie des caractéristiques (sans avoir besoin de posséder une connaissance avancée du domaine). Cependant, nous profiterons des fonctions implémentées dans la première partie de l'exercice pour accélérer le processus d'analyse, aider à la sélection des caractéristiques les plus pertinentes et identifier l'impact de la création d'une nouvelle caractéristique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4a77bef-61ac-4670-bccf-6f66c40f9333",
      "metadata": {
        "id": "a4a77bef-61ac-4670-bccf-6f66c40f9333"
      },
      "source": [
        "## 1. Gestion des Valeurs Aberrantes et Sélection de Caractéristiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbbf9d0a",
      "metadata": {},
      "source": [
        "### 1.1 Chargement de l'Ensemble de Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83dc2b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_data(\"data/ny_taxi.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f60e087",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e7a1587",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2936380",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérifiez s'il existe des valeurs manquantes\n",
        "data.isna().any(axis=1).sum() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72daa88f",
      "metadata": {},
      "source": [
        "### 1.2 Gestion des Valeurs Aberrantes et Sélection de Caractéristiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d082e791",
      "metadata": {},
      "source": [
        "Nous allons effectuer une détection et une suppression des valeurs aberrantes. Pour ce faire, vous devrez compléter la fonction `remove_outliers_iqr()` dans le fichier `hw4.py`. Cette fonction appliquera la méthode de la plage interquartile (IQR) pour la détection des valeurs aberrantes. La méthode IQR définit les valeurs aberrantes comme des points de données qui tombent en dessous de Q1 - 1,5 * IQR ou au-dessus de Q3 + 1,5 * IQR, où Q1 et Q3 sont les 25e et 75e percentiles, respectivement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d7fb42",
      "metadata": {},
      "source": [
        "Ici, nous déciderons de travailler avec les caractéristiques numériques associées aux positions de prise en charge et de dépose et au nombre de passagers, nous ignorerons donc les colonnes `key` et `pickup_datetime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98123f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Les caractéristiques que nous examinerons pour les valeurs aberrantes :\n",
        "base_features = ['pickup_longitude',\n",
        "                 'pickup_latitude',\n",
        "                 'dropoff_longitude',\n",
        "                 'dropoff_latitude',\n",
        "                 'passenger_count']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d44315f",
      "metadata": {},
      "source": [
        "Nous utiliserons notre fonction `remove_outlier_iqr()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c822710",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : compléter la méthode remove_outliers_iqr() dans hw4.py.\n",
        "clean_data = remove_outliers_iqr(data,base_features,\"fare_amount\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a36118",
      "metadata": {},
      "source": [
        "**Question 2**\n",
        "\n",
        "2-. Quels sont les avantages et les inconvénients de la méthode IQR que nous avons mise en œuvre ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb044c91",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33881118",
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2b5eec",
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d271346a",
      "metadata": {},
      "source": [
        "Maintenant, nous allons diviser notre ensemble de données en ensembles d'entraînement et de validation. Nous ne travaillerons qu'avec les colonnes indiquées dans la variable `selected_columns`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096d2e73",
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_columns = ['fare_amount','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']\n",
        "\n",
        "X_train_2, X_val_2, y_train_2, y_val_2 = split_data(clean_data[selected_columns], \"fare_amount\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a9e23e",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99cb4ded",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e91a3f",
      "metadata": {},
      "source": [
        "Next, we will train our random forest regressor model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8b50bf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "secondModel = RandomForestRegressor(n_estimators=50, random_state=1).fit(X_train_2, y_train_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44318352",
      "metadata": {},
      "source": [
        "**Question 3**\n",
        "\n",
        "3-. (Sans effectuer aucune analyse) Quelles caractéristiques semblent potentiellement utiles pour prédire les tarifs de taxi ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa1b268a",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c21829",
      "metadata": {},
      "source": [
        "Utilisons notre fonction `compute_permutation_importance()` pour découvrir quelles caractéristiques sont utilisées par le modèle pour effectuer la prédiction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3996414c",
      "metadata": {},
      "outputs": [],
      "source": [
        "perm_2 = calculate_permutation_importance(secondModel,X_val_2, y_val_2)\n",
        "eli5.show_weights(perm_2, feature_names = X_val_2.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eeed6b8",
      "metadata": {},
      "source": [
        "Avant de voir ces résultats, nous aurions pu nous attendre à ce que chacune des 4 caractéristiques directionnelles soit également importante.\n",
        "\n",
        "Cependant, en moyenne, les caractéristiques de latitude ont plus d'importance que les caractéristiques de longitude.\n",
        "\n",
        "Nous remarquons également que nous pouvons cesser de travailler avec la caractéristique `passenger_count`, car il semble que ce soit la moins pertinente parmi nos caractéristiques."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788a05d9",
      "metadata": {},
      "source": [
        "**Question 4**\n",
        "\n",
        "4-. Pouvez-vous émettre des hypothèses à ce sujet ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7efe31b",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c80ca2ec-6fbd-4974-b600-77ee90782a54",
      "metadata": {
        "id": "c80ca2ec-6fbd-4974-b600-77ee90782a54"
      },
      "source": [
        "### 1.3 Ingénierie des Caractéristiques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d680414",
      "metadata": {},
      "source": [
        "Sans une connaissance détaillée de la ville de New York, il est difficile d'exclure la plupart des hypothèses sur la raison pour laquelle les caractéristiques de latitude ont plus d'importance que les caractéristiques de longitude.\n",
        "\n",
        "Une bonne prochaine étape consiste à dissocier l'effet d'être dans certaines parties de la ville de l'effet de la distance totale parcourue.\n",
        "\n",
        "Nous allons effectuer une ingénierie des caractéristiques, ce qui signifie que nous allons créer de nouvelles caractéristiques pour la distance longitudinale et latitudinale. Ensuite, nous construirons un nouveau modèle pour prédire le montant de la course, qui utilisera les caractéristiques existantes et les nouvelles caractéristiques que nous avons créées.\n",
        "\n",
        "Complétez la fonction `add_absolute_coordinate_changes()` dans `hw4.py`. Elle devrait prendre notre cadre de données `clean_data` et renvoyer un nouveau cadre de données avec deux nouvelles colonnes appelées `abs_lat_change` et `abs_lon_change`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd54aa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO : compléter la méthode add_absolute_coordinate_changes() dans hw4.py.\n",
        "new_c_data = add_absolute_coordinate_changes(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3710e8c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "new_c_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf700f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "features_2  = ['fare_amount','pickup_longitude',\n",
        "               'pickup_latitude',\n",
        "               'dropoff_longitude',\n",
        "               'dropoff_latitude',\n",
        "               'abs_lat_change',\n",
        "               'abs_lon_change']\n",
        "X_train_3, X_val_3, y_train_3, y_val_3 = split_data(new_c_data[features_2], \"fare_amount\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237470b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e12fd82",
      "metadata": {},
      "source": [
        "Nous allons entraîner un deuxième modèle avec les nouvelles caractéristiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb11540",
      "metadata": {},
      "outputs": [],
      "source": [
        "thirdModel = RandomForestRegressor(n_estimators=30, random_state=1).fit(X_train_3, y_train_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92a74d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "perm_3 = calculate_permutation_importance(thirdModel, X_val_3, y_val_3)\n",
        "eli5.show_weights(perm_3, feature_names = X_val_3.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa29ca24",
      "metadata": {},
      "source": [
        "**Question 5**\n",
        "\n",
        "5-. Comment interpréteriez-vous ces scores d'importance ? Il semble que la distance parcourue soit beaucoup plus importante que les effets de localisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a1ce7a",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9368e24b",
      "metadata": {},
      "source": [
        "**Question 6**\n",
        "\n",
        "6-. Vous avez vu que l’importance des caractéristiques pour la distance latitudinale est plus grande que l’importance de la distance longitudinale. De là, pouvons-nous conclure si voyager sur une distance latitudinale fixe tend à être plus cher que de voyager sur la même distance longitudinale ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1833815e",
      "metadata": {},
      "source": [
        "*Votre réponse ici*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
